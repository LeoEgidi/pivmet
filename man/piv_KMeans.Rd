% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/musk.R
\name{piv_KMeans}
\alias{piv_KMeans}
\title{K-means Clustering Using Pivotal Algorithms For Seeding}
\usage{
piv_KMeans(x, centers, alg.type = c("KMeans", "hclust"),
  piv.criterion = c("MUS", "maxsumint", "maxsumnoint", "maxsumdiff"),
  H = 1000, ...)
}
\arguments{
\item{x}{A \eqn{N \times D} data matrix, or an object that can be coerced to such a matrix (such as a numeric vector or a dataframe with all numeric columns).}

\item{centers}{The number of clusters in the solution.}

\item{alg.type}{The clustering algorithm for the initial partition of the
\eqn{N} units into the desired number of clusters.
Possible choices are \code{"KMeans"} and \code{"hclust"}.}

\item{piv.criterion}{The pivotal criterion used for identifying one pivot
for each group. Possible choices are: \code{"MUS", "maxsumint", "maxsumnoint",
"maxsumdiff"}.
If \code{centers <= 4}, the default method is \code{"MUS"};
otherwise, the default method is \code{"maxsumdiff"} (see the details and
the vignette).}

\item{H}{If \code{MUS} is selected, this is the number of
distinct k-means partitions used for building a \eqn{N \times N}
co-association matrix.}

\item{...}{Optional arguments.}

\item{iter.max}{The maximum number of iterations allowed.}

\item{num.seeds}{The number of different starting random seeds to use. Each random seed results in a different k-means solution.}
}
\value{
A list with components

\item{\code{cluster}}{A vector of integers indicating the cluster to which each point is allocated.}
\item{\code{centers}}{A matrix of cluster centres (centroids).}
\item{\code{totss}}{The total sum of squares.}
\item{\code{withinss}}{The within-cluster sum of squares for each cluster.}
\item{\code{tot.withinss}}{The within-cluster sum of squares summed across clusters.}
\item{\code{betwennss}}{The between-cluster sum of squared distances.}
\item{\code{size}}{ The number of points in each cluster.}
\item{\code{iter}}{The number of (outer) iterations.}
\item{\code{ifault}}{integer: indicator of a possible algorithm problem â€“ for experts.}
\item{\code{pivots}}{The pivotal units identified by the selected pivotal criterion.}
}
\description{
Perform classical k-means clustering on a data matrix using pivots as
initial centers.
}
\details{

}
\examples{

# Data generated from a mixture of three bivariate Gaussian distributions

N  <- 620
k  <- 3
n1 <- 20
n2 <- 100
n3 <- 500
x  <- matrix(NA, N,2)
truegroup <- c( rep(1,n1), rep(2, n2), rep(3, n3))

for (i in 1:n1){
 x[i,]=rmvnorm(1, c(1,5), sigma=diag(2))}
for (i in 1:n2){
 x[n1+i,]=rmvnorm(1, c(4,0), sigma=diag(2))}
for (i in 1:n3){
 x[n1+n2+i,]=rmvnorm(1, c(6,6), sigma=diag(2))}

# Apply piv_KMeans with MUS as pivotal criterion

res <- piv_KMeans(x, k)

# Apply piv_KMeans with maxsumdiff as pivotal criterion

res2 <- piv_KMeans(x, k, piv.criterion ="maxsumdiff")

# Plot the data and the clustering solution

par(mfrow=c(1,2), pty="s")
colors_cluster <- c("grey", "darkolivegreen3", "coral")
colors_centers <- c("black", "darkgreen", "firebrick")
plot(x, col = colors_cluster[truegroup],
   bg= colors_cluster[truegroup], pch=21, xlab="x[,1]",
   ylab="x[,2]", cex.lab=1.5,
   main="True data", cex.main=1.5)

plot(x, col = colors_cluster[res$cluster],
   bg=colors_cluster[res$cluster], pch=21, xlab="x[,1]",
   ylab="x[,2]", cex.lab=1.5,
   main="piv_KMeans", cex.main=1.5)
points(x[res$pivots[1],1], x[res$pivots[1],2],
   pch=24, col=colors_centers[1],bg=colors_centers[1],
   cex=1.5)
points(x[res$pivots[2],1], x[res$pivots[2],2],
   pch=24,  col=colors_centers[2], bg=colors_centers[2],
   cex=1.5)
points(x[res$pivots[3],1], x[res$pivots[3],2],
   pch=24, col=colors_centers[3], bg=colors_centers[3],
   cex=1.5)
points(res$centers, col = colors_centers[1:k],
   pch = 8, cex = 2)
}
\author{
Leonardo Egidi \url{legidi@units.it}
}
