---
title: "Dealing with label switching: relabelling in Bayesian mixtures by pivotal units"
author: "Leonardo Egidi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: ref.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this vignette we explore the relabelling pivotal method explained in @egidi2018relabelling the `pivrel` package. There are two main functions designed for our procedure: 

- `bayesMCMC` performs MCMC sampling via the `runjags` 
package. At the end, the chains are post-processed and randomly swithed. Moreover, the same function builds a co-association matrix $C$ for the $n$ statistical units, clusters them into $k$ (prespecified) groups and extracts the pivotal units, one for each group.

- `pivotal_relabelling` performs the relabelling algorithm using the $k$ pivotal units as groups identifiers. It yields the relabelled chains and the corresponding posterior estimates.

## Example: bivariate data

Suppose $\boldsymbol{y}_i \sim \sum_{j=1}^{k}\pi_{k}\mathcal{N}_{2}(\boldsymbol{\mu}_{k}, \boldsymbol{\Sigma})$. Through the function `sim_mixture`, we may generate Gaussian mixture data, specifying the desired number of groups $k$. The argument `W` specifies the weights for a nested mixture, in which each $j$-th component is in turn modelled as a two-component mixture.


```{r sim function, echo = FALSE, message =FALSE, warning=FALSE}
library(mvtnorm)
library(runjags)
library(rjags)
library(cluster)
library(mclust)
library(MCMCpack)
library(Rcmdr)

sim_mixture <- function(N,k,Mu, stdev,Sigma.p1,Sigma.p2,W){
  # Generation---------------

  if (is.vector(Mu)){
    true.group <- sample(1:k,N,replace=TRUE,prob=rep(1/k,k))
    Spike <- array()
    matrixpi <- matrix(rep(W,k), nrow=k, ncol=2, byrow = T)
    sotto.gruppi <- matrix(0, nrow=k, ncol=N)
    y <- c()

    for (i in 1:N){
      sotto.gruppi[,i] <- sample(1:2, k, replace=T,
        prob=matrixpi[true.group[i],])
      y[i] <- rnorm(1, mean=Mu[true.group[i]],
                       sd=stdev[sotto.gruppi[true.group[i],i]])
    }

  }else{


    true.group <- sample(1:k,N,replace=TRUE,prob=rep(1/k,k))
    Spike <- array(c(Sigma.p1,Sigma.p2), dim=c(2,2,2))
    # Probability matrix of subgroups
    matrixpi <- matrix(rep(W,k), nrow=k, ncol=2, byrow = T)
    sotto.gruppi <- matrix(0, nrow=k, ncol=N)

  for (i in 1:N){
    sotto.gruppi[,i] <- sample(1:2,k,replace=T,
      prob=matrixpi[true.group[i],])
  }

  # Simulation of N units from a mixture of mixtures
  y <- matrix(NA,nrow=N,ncol=2)

  for (i in 1:length(true.group)){
    y[i,] <- mvrnorm(1, Mu[true.group[i],],
      Sigma=Spike[,,sotto.gruppi[true.group[i],i]])
  }
}

return(list(y=y, true.group=true.group, subgroups=sotto.gruppi))
}

pivotal_selection<-function(Obj, k, gIndex, C, n, ZM, maxima, available_met){

  if (missing(maxima)){
    maxima=c(1:k)
  }

Cg1 <- rep(NA, k)
Cg  <- matrix(NA, ncol=available_met, nrow=k)

 for (g.i in 1:k){
    com.gi  <-  (1:n)[gIndex==g.i]
    com.ngi <-  (1:n)[gIndex!=g.i]
    ind.gi  <- c()
    ind.gi1 <- c()


# choose the pivots within each group
  for (j in com.gi){
      ind.gi  <- rbind(ind.gi,c(j,sort(C[j,com.gi],
        decreasing=TRUE)))
      ind.gi1 <- rbind(ind.gi1,c(j,
        # criteria involving maximization
        #max(C[j,com.gi],na.rm=TRUE),          #dropped
        sum(C[j,com.gi],na.rm=TRUE),           #maxsumint
        # criteria involving minimization
        #min(C[j,com.gi],na.rm=TRUE),          #dropped
        #min(C[j,com.ngi]),                    #dropped
        sum(C[j,com.ngi]),                     #maxsumnoint
        # another criterion involving maximization
        sum(C[j,com.gi],na.rm=TRUE)-sum(C[j,com.ngi])))
  }                                            #maxsumdiff

# Methods: from 1 to 4
    # if (!is.null(ind.gi))
    #   Cg[g.i, 1] <- com.gi[which.max(ind.gi1[,2])]
    if (!is.null(ind.gi))
      Cg[g.i, 1] <- com.gi[which.max(ind.gi1[,2])]
    if (!is.null(ind.gi))
      Cg[g.i, 2] <- com.gi[which.min(ind.gi1[,3])]
    if (!is.null(ind.gi))
      Cg[g.i, 3] <- com.gi[which.min(ind.gi1[,4])]
    # if (!is.null(ind.gi))
    #   Cg[g.i, 5] <- com.gi[which.min(ind.gi1[,6])]
    # if (!is.null(ind.gi))
    #   Cg[g.i, 6] <- com.gi[which.max(ind.gi1[,7])]
    if (available_met==4){
    if (!is.null(ind.gi))
      Cg[, 4]    <-  t(maxima)
    }
    if (!is.null(ind.gi)){
      Cg1[g.i] <- ind.gi[do.call(order,
        as.data.frame(-ind.gi[,-1]))[1],1]
    }
  }

# For each method, we store the selected pivotal units
Cg <- Cg[,Obj]
# group1 contains the observation assigments to the groups obtained via pivots
group1 <- 0*ZM
# cycle on iterations
  for (i in 1:ncol(ZM)){
# cycle on number of groups
    for (j in 1:k){
      if (!is.na(Cg[j])){
        group1[ZM[,i] ==ZM[Cg[j],i],i] <- j
      }
    }
  }

# definition of the probabilities to belong to the groups for each unit
pr <- matrix(NA,nrow=k,ncol=n)
 for (kk in 1:k){
  pr[kk,] <- apply(group1,1,FUN=function(x) sum(x==kk)/length(x))
 }

# definition of the submatrix corresponding to the pivotal units

submatrix <- round(C[Cg,Cg],5)
T <- max(submatrix[upper.tri(submatrix)])

  return(list(pr=pr, Cg=Cg, Submatrix=submatrix, Max=T))
}





```


```{r nested}
N <- 200
k <- 3
nMC <- 5000
M1  <- c(-.5,8)
M2  <- c(25.5,.1)
M3  <- c(49.5,8)
Mu  <- matrix(rbind(M1,M2,M3),c(k,2))
stdev <- cbind(rep(1,k), rep(200,k))
Sigma.p1 <- matrix(c(stdev[1,1],0,0,stdev[1,1]),
                   nrow=2, ncol=2)
Sigma.p2 <- matrix(c(stdev[1,2],0,0,stdev[1,2]),
                   nrow=2, ncol=2)
W <- c(0.2,0.8)
sim <- sim_mixture(N=N,k=k,Mu=Mu,stdev=stdev,
  Sigma.p1=Sigma.p1, Sigma.p2=Sigma.p2,W=W)

```

The function ```bayesMCMC``` requires only three mandatory arguments: data ```y```, number of component ```k``` and number of MCMC iterations ```nMC```. It performs JAGS sampling using the ```bayesmix``` package for univariate data and ```runjags``` package for bivariate data. After $H$ MCMC iterations, the function implements a clustering procedure on $k$ groups---through the optional argument `clustering` the user may choose among agglomerative or divisive hierarchical clustering---. Using the latent formulation for mixture models, we denote with $[Z_i]_h$ the group allocation of the $i$-th unit at the $h$-th iteration. The function builds a co-association matrix $C$ across the MCMC sample with generic element:

$$c_{ip} = \frac{n_{ip}}{H}=\frac{1}{H} \sum_{h=1}^{H}|[Z_i]_h=[Z_p]_h|,$$

where $|\cdot|$ denotes the event indicator and $n_{ip}$ is the number of times the units $i, \ p$ belong to the same group along the sampling. Using this matrix, we may extract some units, one for each group, which
are (pairwise) separated with (posterior) probability one (that
is, the posterior probability of any two of them being in the
same group is zero). We call them *pivots*, and denote them with: $i_1,\ldots,i_k$. With the optional argument `piv.criterion`, the user may choose among three (plus one) procedures for extracting the pivotal units. For group $j$ containing $J_j$ units, one can choose:

-  $i^{*}$ that maximizes $\sum_{p \in J_j}c_{ip}$ (`maxsumint`);

- $i^{*}$ that maximizes $\sum_{p \in J_j}c_{ip}- \sum_{p \not\in J_j}c_{ip}$ (`maxsumdiff`);

- $i^{*}$ that minimizes $\sum_{p \not\in J_j}c_{ip}$ (`maxsumnoint`).

Alternatively, when $k <5$, the user has the optional pivotal criterion `MUS` [@egidi2018mus] based on a sequential search within the matrix $C$.


```{r bayesMCMC, echo = FALSE}
bayesMCMC <- function(y, k, nMC, piv.criterion,
  clustering){

  # Conditions about data dimension----------------

  if (is.vector(y)){
    N <- length(y)
    # JAGS code------------------------

    # Initial values
    mu_inits<- c()
    clust_inits <- kmeans(y, k)$cluster
    for (j in 1:k){
      mu_inits[j]<-mean(y[clust_inits==j])
    }
    # Data
    burn <- 1000

    # Model
    mod.mist.univ <- BMMmodel(y, k = k, initialValues = list(S0 = 2),
      priors = list(kind = "independence", parameter = "priorsFish",
        hierarchical = "tau"))
    control <- JAGScontrol(variables = c("mu", "tau", "eta", "S"),
      burn.in = burn, n.iter = nMC, seed = 10)
    ogg.jags <- JAGSrun(y, model = mod.mist.univ, control = control)
    # Parameters' initialization

    J <- 3
    mcmc.pars <- array(data = NA, dim = c(nMC-length(1:burn), k, J))
    mcmc.pars[ , , 1] <- ogg.jags$results[-(1:burn), (N+k+1):(N+2*k)]
    mcmc.pars[ , , 2] <- ogg.jags$results[-(1:burn), (N+2*k+1):(N+3*k)]
    mcmc.pars[ , , 3] <- ogg.jags$results[-(1:burn), (N+1):(N+k)]

    mu_pre_switch_compl <-  mcmc.pars[ , , 1]
    tau_pre_switch_compl <-  mcmc.pars[ , , 2]
    prob.st_pre_switch_compl <-  mcmc.pars[ , , 3]

    mu <- mcmc.pars[,,1]
    tau <- mcmc.pars[,,2]
    prob.st <- mcmc.pars[,,3]
    group <-  ogg.jags$results[-(1:burn), 1:N] #gruppi
    FreqGruppiJags <- table(group)
    numeffettivogruppi <- apply(group,1,FUN = function(x) length(unique(x)))

    if (sum(numeffettivogruppi==k)==0){
      return(print("MCMC has not never been able to identify the required number of groups and the process has been interrupted"))
      #return(1)
    }

    ##saved in the output
    ris_prel <- ogg.jags$results[-(1:burn),]
    ris <- ris_prel[numeffettivogruppi==k,]
    true.iter <- nrow(ris)
    group <- ris[,1:N]

    group.orig <- group
    verigruppi <- as.double(names(table(group)))

    cont <- 0
    for (verogruppo in verigruppi){
      cont <- cont+1
      group.orig[group==verogruppo] <- cont          #aggiorna contatore pivot
    }
    cont                                           #qualche dubbio su sta parte

    k.orig <- k
    if (cont>1){
      k <- cont
    }
    mu <- mu[,verigruppi]
    tau <- tau[,verigruppi]
    prob.st <- prob.st[,verigruppi]

    M <- nrow(group)
    group <- group*0
    mu_switch <- array(rep(0, true.iter*k), dim=c(true.iter,k))
    z <- array(0,dim=c(N, k, true.iter))

    for (i in 1:true.iter){
      perm <- sample(1:k,k,replace=FALSE)
      for (j in 1:k){
        #post-processing
        group[i,group.orig[i,]==j] <- perm[j]
      }
      mu_switch[i,] <- mu[i,perm]
      tau[i,] <- tau[i,perm]
      prob.st[i,] <- prob.st[i,perm]
    }

    for (i in 1:true.iter){
      for (j in 1:N){
        z[j,group[i,j],i] <- 1
      }
    }


  }else if (is.matrix(y)){
    N <- dim(y)[1]

    # JAGS code------------------------

    # Initial values
    mu0 <- as.vector(c(0,0))
    S2 <- matrix(c(1,0,0,1),nrow=2)/100000
    S3 <- matrix(c(1,0,0,1),nrow=2)/100000

    # Data
    dati.biv <- list(y = y, N = N, k = k, S2= S2, S3= S3, mu0=mu0,
      onesRepNclust = rep(1,k))

    # Model
    mod.mist.biv<-"model{
    # Likelihood:

    for (i in 1:N){
    yprev[i,1:2]<-y[i,1:2]
    y[i,1:2] ~ dmnorm(muOfClust[clust[i],],tauOfClust)
    clust[i] ~ dcat(pClust[1:k] )
    }

    # Prior:

    for (g in 1:k) {
    muOfClust[g,1:2] ~ dmnorm(mu0[],S2[,])}
    tauOfClust[1:2,1:2] ~ dwish(S3[,],3)
    Sigma[1:2,1:2] <- inverse(tauOfClust[,])
    pClust[1:k] ~ ddirch( onesRepNclust)
  }"


    # Parameters' initialization
    clust_inits <- KMeans(y, k)$cluster
    #cutree(hclust(dist(y), "average"),k)
    mu_inits <- matrix(0,k,2)
    for (j in 1:k){
      mu_inits[j,] <- cbind(mean(y[clust_inits==j,1]), mean(y[clust_inits==j,2]))
    }
    #Reorder mu_inits according to the x-coordinate
    mu_inits <-
      mu_inits[sort(mu_inits[,1], decreasing=FALSE, index.return=TRUE)$ix,]

    init1.biv <- dump.format(list(muOfClust=mu_inits,
      tauOfClust= matrix(c(15,0,0,15),ncol=2),
      pClust=rep(1/k,k), clust=clust_inits))
    moni.biv <- c("clust","muOfClust","tauOfClust","pClust")

    mod   <- mod.mist.biv
    dati  <- dati.biv
    init1 <- init1.biv
    moni  <- moni.biv

    # Jags execution
    ogg.jags <- run.jags(model=mod, data=dati, monitor=moni,
      inits=init1, n.chains=3,plots=FALSE, thin=1,
      sample=nMC, burnin=1000)
    # Extraction
    ris <- ogg.jags$mcmc[[1]]

    # Post- process of the chains----------------------
    group <- ris[,grep("clust[",colnames(ris),fixed=TRUE)]
    M <- nrow(group)
    H <- list()

    mu_pre_switch_compl <- array(rep(0, M*2*k), dim=c(M,2,k))
    for (i in 1:k){
      H[[i]] <- ris[,grep("muOfClust",colnames(ris),fixed=TRUE)][,c(i,i+k)]
    }
    for (i in 1:k){
      mu_pre_switch_compl[,,i] <- as.matrix(H[[i]])
    }
    # Discard iterations
    numeffettivogruppi <- apply(group,1,FUN = function(x) length(unique(x)))
    ris <- ris[numeffettivogruppi==k,]
    true.iter <- nrow(ris)

    if (sum(numeffettivogruppi==k)==0){
      return(print("MCMC has not never been able to identify the required number of groups and the process has been interrupted"))
      #return(1)
    }else{
      L<-list()
      mu_pre_switch <- array(rep(0, true.iter*2*k), dim=c(true.iter,2,k))
      for (i in 1:k){
        L[[i]] <- ris[,grep("muOfClust",colnames(ris),fixed=TRUE)][,c(i,i+k)]
      }
      for (i in 1:k){
        mu_pre_switch[,,i] <- as.matrix(L[[i]])
      }
    }

    group <- ris[,grep("clust[",colnames(ris),fixed=TRUE)]
    FreqGruppiJags <- table(group)
    tau <- ris[,grep("tauOfClust[",colnames(ris),fixed=TRUE)]
    prob.st <- ris[,grep("pClust[",colnames(ris),fixed=TRUE)]
    group.orig <- group
    verigruppi <- as.double(names(table(group)))
    prob.st <- prob.st[,verigruppi]

    mu_pre_switch <- mu_pre_switch[,,verigruppi]

    # Switching Post
    cont <- 0
    for (l in verigruppi){
      cont <- cont+1
      group.orig[group==l] <- cont
    }
    k.orig <- k
    if (cont > 1){
      k <- cont
    }
    mu_switch <- array(rep(0, true.iter*2*k), dim=c(true.iter,2,k))
    group <- group*0
    z <- array(0,dim=c(N, k, true.iter))

    for (i in 1:true.iter){
      perm <- sample(1:k,k,replace=FALSE)
      for (j in 1:k){
        #post-processing
        group[i,group.orig[i,]==j] <- perm[j]
      }
      mu_switch[i,,] <- mu_pre_switch[i,,perm]
      #tau[i,] <- tau[i,perm]
      prob.st[i,] <- prob.st[i,perm]
    }

    for (i in 1:true.iter){
      for (j in 1:N){
        z[j,group[i,j],i] <- 1
      }
    }

}

  FreqGruppiJagsPERM <- table(group)
  Freq <- cbind(FreqGruppiJags,FreqGruppiJagsPERM)



  # Similarity matrix based on MCMC sampling------------------------
  nz <- dim(z)[1]
  M <- dim(z)[3]
  C <- matrix(1,nz,nz)
  zm <- apply(z,c(1,3),FUN=function(x) sum(x*(1:length(x))))

  for (i in 1:(nz-1)){
    for (j in (i+1):nz){
      C[i,j] <- sum(zm[i,]==zm[j,])/M
      C[j,i] <- C[i,j]
    }
  }
  matdissim <- 1-C
  diag(matdissim) <- 0

  # Clustering on dissimilarity matrix-------------

  if (missing(clustering)){
    #clustering <- "diana"
    gr  <- diana(matdissim,diss=TRUE)
    grr <- cutree(gr, k)
  }else if(clustering =="diana"){
    gr  <- diana(matdissim,diss=TRUE)
    grr <- cutree(gr, k)
  }else if(clustering == "hclust"){
    gr  <- hclust(as.dist(matdissim))
    grr <- cutree(gr, k)
  }

  available_met <- 3

  piv.criterion.choices <- c("maxsumint", "maxsumnoint",
    "maxsumdiff")

  if (missing(piv.criterion)){
    piv.criterion <- "maxsumdiff"
  }

  if (piv.criterion=="maxsumint"||
      piv.criterion=="maxsumnoint"||
      piv.criterion=="maxsumdiff" ){

    piv.index <- (1:3)[piv.criterion.choices==piv.criterion]
    piv.index.pivotal <- c(1,2,3)
    available_met <- 3
    x <- c(1:available_met)
    prec.par.1 <- min(min(table(grr))-1,5)
    clust  <- lapply(x, pivotal_selection,
      k=k, gIndex=as.vector(grr),
      C=C, n=nz, ZM=zm,
      available_met = available_met)

    clust_sel <- clust[[piv.index.pivotal[piv.index]]]
  }else if(piv.criterion=="MUS"){
      if (k <=4 & sum(C==0)!=0){
          available_met <- 4
          x <- c(1:available_met)
          prec.par.1 <- min(min(table(grr))-1,5)
          mus_res    <- MUS(C, grr, prec.par.1)
         clust  <- lapply(x, pivotal_selection,
             k=k, gIndex=as.vector(grr),
             C=C, n=nz, ZM=zm,
             maxima=mus_res$maxima,
             available_met = available_met)
         clust_sel <- clust[[4]]
    }
  }else{

    x <- c(1:available_met)
    clust  <- lapply(x, pivotal_selection,
      k=k, gIndex=as.vector(grr),
      C=C, n=nz, ZM=zm,
      available_met = available_met)
    clust_sel <- clust[[3]]
  }
  PivotIndex <- list()
  #for(i in 1:length(x)){
    PivotIndex[[1]] <- clust_sel$Cg
  #}


  return(list( Freq=Freq, z=z, Mu = mu_inits,
    ris=ris, groupPost=group,
    mu_switch=mu_switch,
    mu_pre_switch_compl=mu_pre_switch_compl,
    C=C, grr=grr, clust_sel =clust_sel,
    true.iter = true.iter,
    piv.criterion = piv.criterion))
  }
```




```{r mcmc, message =  FALSE, warning = FALSE}
output_bayes <- bayesMCMC(sim$y, k, nMC)
```

Once we obtain posterior estimates, label switching is likely to occurr. For such a reason, we need to relabel our chains, and the pivotal units previously detected play a central role, yielding to the following relabelling:

\begin{align*} 
[\mu_{j}]_h=&[\mu_{Z_{i_{j}}}]_h \\
[Z_{i}]_h =j & \mbox{ for } i : [Z_i]_h=[Z_{i_{j}}]_h.\\
\end{align*}

The function `pivotal_relabelling` performs the procedure above, taking the raw chains and the latent allocation vector as main inputs. After this, we may plot the relabelled chains through the options `chains` of the argument `type` of the function `plot_pivotal`. 

```{r relab, echo =FALSE}
pivotal_relabelling<-function(mu_switch, group, clustering,
  Mu, nMC ){

  true.iter <- dim(mu_switch)[1]
  groupD <- array(NA, dim=c(true.iter, N))

  # cycle on number of iterations
  for (i in 1:true.iter){
      # cycle on number of groups
    for (j in 1:k){
     groupD[i, group[i,]==group[i, clustering$Cg[j]]] <- j
        #group[i, clustering[[u]]$Cg[j]]
     }
    }
  # Finding final number of iterations : H_{G}-H^{*}_G, as explained     in the paper
  contD <- c()
  for (i in 1:true.iter){
      contD[i] <- sum(is.na(groupD[i,])==TRUE)
    }

# Final_It contains the final valid number of iterations


 if (length(dim(mu_switch))==2){
    k <- dim(mu_switch)[2]
    mu_rel_median     <- c()  #vector of length k
    mu_rel_mean       <- c()
    mu_rel_median_tr  <- c()
    mu_rel_mean_tr    <- c()
    groupD2           <- groupD[contD==0,]
    mu_switchD        <- mu_switch[contD==0,]
    true.iterD2       <- sum(contD==0)
    Final_It          <- true.iterD2/nMC
    mu_rel_complete   <- matrix(NA,true.iterD2, k)


    if (true.iterD2!=0){
      for (m in 1:true.iterD2){
        for ( j in 1:k){
          vect_rel <- sort(mu_switchD[m,],
            decreasing=FALSE, index.return=TRUE)$ix
            mu_rel_complete[m,j] <-
              mu_switchD[m,
                vect_rel[groupD2[m, clustering$Cg[j]]] ]
          }
        }
      }else{
        mu_rel_median <- rep(NA,k)
        mu_rel_mean   <- rep(NA,k)
      }

      mu_rel_median  <- apply(mu_rel_complete, 2, median)
      mu_rel_mean    <- apply(mu_rel_complete, 2, mean)
      mu_rel_median_tr  <- t(mu_rel_median)
      mu_rel_mean_tr    <- t(mu_rel_mean)

  }else{
    k <- dim(mu_switch)[3]
    mu_rel_median  <- array(NA,c(2,k))
    mu_rel_mean    <- array(NA,c(2,k))
    groupD2        <- groupD[contD==0,]
    mu_switchD     <- mu_switch[contD==0,,]
    true.iterD2    <- sum(contD==0)
    Final_It       <- true.iterD2/nMC
    mu_rel_complete  <- array(NA, dim=c(true.iterD2, 2,k))


      if (true.iterD2!=0){
        for (m in 1:true.iterD2){
          for (j in 1:k){
            mu_rel_complete[m,,j] <-
              mu_switchD[m,,groupD2[m,clustering$Cg[j]]]
          }
        }
      }else{
        mu_rel_median <- matrix(NA,c(2,k))
        mu_rel_mean   <- matrix(NA,c(2,k))

      }

    ind <- array(NA, c( nrow(mu_rel_complete) ,2, k))
      for (g in 1:nrow(mu_rel_complete)){
        prel1 <- c()
        prel2 <- c()
        for (h in 1:k){
    prel1[h] <- which.min((mu_rel_complete[g,1,]-Mu[h,1])^2)
    prel2[h] <- which.min((mu_rel_complete[g,2,]-Mu[h,2])^2)
         }
        ind[g,1,] <- prel1
        ind[g,2,] <- prel2
      }

    mu_rel_median_tr  <- array(NA, c(k,2))
    mu_rel_mean_tr    <- array(NA, c(k,2))

 for (h in 1:nrow(mu_rel_complete)){
  mu_rel_complete[h,1,] <- mu_rel_complete[h,1, ind[h,1,]]
  mu_rel_complete[h,2,] <- mu_rel_complete[h,2, ind[h,2,]]
      }
  mu_rel_median    <- apply(mu_rel_complete, c(2,3), median)
  mu_rel_mean      <- apply(mu_rel_complete, c(2,3), mean)
  mu_rel_median_tr <- t(mu_rel_median)
  mu_rel_mean_tr   <- t(mu_rel_mean)
    }

 return(list(mu_rel_median = mu_rel_median_tr,
              mu_rel_mean = mu_rel_mean_tr,
              mu_rel_complete = mu_rel_complete,
              Final_It = Final_It))
}


plot_pivotal <- function(y, est, chains,
  type, mu_switch, n.iter, true.means ){
  colori <- c("red", "green", "violet", "blue")

  if (type=="chains" ){
    if (length(dim(mu_switch))==2){

      k <- dim(mu_switch)[2]
      par(mfrow=c(1,2), oma=c(0,0,0,0))
      #plot
      matplot(mu_switch, type="l", xlab="Iterations",
        ylab=expression(mu), main="Raw MCMC chains",
        cex.main=0.8)
      #plot the relabeled
      matplot(chains, type="l",
        xlab="Iterations",
        ylab=expression(mu),
        main=paste("Rel. chains"), cex.main=0.8)
    }else{
      k <- dim(mu_switch)[3]
      par(mfrow=c(2,2), oma=c(0,0,0,0))
      matplot(mu_switch[,1,], type="l", xlab="Iterations",
        ylab=expression(mu[1]), main="Raw MCMC chains",
        cex.main=0.8 )
      #plot the second component
      matplot(mu_switch[,2,], type="l", xlab="Iterations",
        ylab=expression(mu[2]), main="Raw MCMC chains",
        cex.main=0.8)

      #plot the first relabelled component
      matplot(chains[,1,],type="l", xlab="Iterations",
        ylab=expression(mu[1]),
        main=paste("Rel.chains"), cex.main=0.8)

      #plot the second relabelled component
      matplot(chains[,2,],type="l", xlab="Iterations",
        ylab=expression(mu[2]),
        main=paste("Rel. chains"), cex.main=0.8)
    }

  }
  #else if(type=="chains" & all(pivotal.criterion, c(1:6))){
  #   if (length(dim(mu_switch))==2){
  #
  #     k <- dim(mu_switch)[2]
  #     par(mfrow=c(3,2), oma=c(0,0,0,0))
  #
  #     #plot the relabeled
  #     for (j in 1:6){
  #     matplot(chains[[pivotal.criterion[j]]], type="l",
  #       xlab="Iterations",
  #       ylab=expression(mu),
  #       main=paste("Relabelled chains: method", pivotal.criterion[j]))
  #     }
  #
  #   }else{
  #     par(mfrow=c(3,4))
  #
  #     for (j in 1:6){
  #     #plot the first relabelled component
  #     matplot(chains[[pivotal.criterion[j]]][,1,],type="l",
  #       xlab="Iterations",
  #       ylab=expression(mu[1]),
  #       main=paste("Rel. method ", pivotal.criterion[j]))
  #
  #     #plot the second relabelled component
  #     matplot(chains[[pivotal.criterion[j]]][,2,],type="l",
  #       xlab="Iterations",
  #       ylab=expression(mu[2]),
  #       main=paste("Rel. method ", pivotal.criterion[j]) )
  #     }
  #
  #   }
  #
  #
  #}
  else if (type=="estimates"){
    if (length(dim(mu_switch))==2){
      switch.means <- colMeans(mu_switch)
      par(mfrow=c(1,2), oma=c(0,0,0,0), las=1, yaxt="n")
      # raw estimates
      plot( true.means, rep(0.3,length(true.means)),
        axes = FALSE , ylab="",ylim=c(0,1),
        xlim=c( min(true.means,
          est)-2,
          max(true.means,
            est)+2  ),
        main=paste("Raw MCMC estimates" ), cex.main =0.8)
      points(switch.means,
        rep(0, length(true.means)), col="red")
      axis(1)
      axis(1, col = "black", tcl = 0)
      par(yaxt="n")
      axis(2)
      par(yaxt="s")
      axis(2, c(0,0.3), c("Est.", "True"), col = "white", tcl = 0)

      #relabelled estimates
      plot( true.means, rep(0.3,length(true.means)),
        axes = FALSE , ylab="",ylim=c(0,1),
        xlim=c( min(true.means,
          est)-2,
          max(true.means,
            est)+2  ),
        main=paste("Rel. estimates"), cex.main =0.8)
      points(est, rep(0, length(true.means)),
        col="red")
      axis(1)
      axis(1, col = "black", tcl = 0)
      par(yaxt="n")
      axis(2)
      par(yaxt="s")
      axis(2, c(0,0.3), c("Est.", "True"), col = "white", tcl = 0)
    }else{
      par(mfrow=c(1,2), oma =c(0,0,0,0))
      colori<-c("red", "green", "violet", "blue")

      l1<-(3/2)*min(Mu[,1])-max(Mu[,1])/2+5
      l2<-(3/2)*max(Mu[,1])-min(Mu[,1])/2-5
      u1<-(3/2)*min(Mu[,2])-max(Mu[,2])/2
      u2<-(3/2)*max(Mu[,2])-min(Mu[,2])/2

      #plot the raw MCMC estimates
      plot(Mu, xlim=c( min(true.means, est)-2,
        max(true.means,est)+2  ),
        ylim=c(u1,u2), main="Raw MCMC output",
        xlab=expression(mu[1]), ylab=expression(mu[2]))
      points(t(apply(mu_switch, c(2,3), mean)), col="red")
      #for (j in 1:k)
      # points(output_bayes$mu_switch[,,j], col=colori[j])
      #plot relabelled estimates
      plot(Mu, xlim=c( min(true.means, switch.means)-1,
        max(true.means, switch.means)+1  ), ylim=c(u1,u2),
        xlab=expression(mu[1]), ylab=expression(mu[2]),
        main="Relabelled",  pch=3, bg=2)
      points(est, col="red")
    }
  }
  # else if (type=="estimates" & all(pivotal.criterion, c(1:6))){
  #     if (length(dim(mu_switch))==2){
  #       par(mfrow=c(3,2), oma=c(0,0,0,0))
  #       for (j in 1:6){
  #         plot( true.means, rep(0.3,length(true.means)),
  #           axes = FALSE , ylab="",ylim=c(0,1),
  #           xlim=c( min(true.means, est[,pivotal.criterion[j]])-2,
  #             max(true.means, est[,pivotal.criterion[j]])+2  ),
  #           main=paste("Rel. estimates, method", pivotal.criterion[j] ))
  #         points(est[,pivotal.criterion[j]],
  #           rep(0, length(true.means)), col="red")
  #         axis(1)
  #         axis(1, col = "black", tcl = 0)
  #         par(yaxt="n")
  #         axis(2)
  #         par(yaxt="s")
  #         axis(2, c(0,0.3), c("Est.", "True"), col = "white", tcl = 0)
  #       }
  #     }else{
  #     par(mfrow=c(3,2), oma=c(0,0,0,0))
  #     l1<-(3/2)*min(Mu[,1])-max(Mu[,1])/2+5
  #     l2<-(3/2)*max(Mu[,1])-min(Mu[,1])/2-5
  #     u1<-(3/2)*min(Mu[,2])-max(Mu[,2])/2
  #     u2<-(3/2)*max(Mu[,2])-min(Mu[,2])/2
  #
  #
  #      for (j in 1:6){
  #      plot(Mu, xlim=c(l1,l2), ylim=c(u1,u2),
  #        xlab=expression(mu[1]), ylab=expression(mu[2]),
  #        main=paste("Relabelled - method", pivotal.criterion[j], sep=" "),
  #        pch=3, bg=2)
  #      points(est[,,pivotal.criterion[j]], col="red")
  #      }
  #   }
  #
  #   }
  else if(type=="estimates_hist"){
    if (length(dim(mu_switch))==2){
      par(mfrow=c(1,2))
      hist(y, breaks=40, prob = TRUE,
        main ="Raw MCMC estimates", cex.main =0.8)
      points(colMeans(mu_switch), rep(0, length(true.means)),
        col="red", pch=21,  bg="red")
      hist(y, breaks=40, prob = TRUE,
        main=paste("Rel. estimates" ), cex.main=0.8 )
      points(est, rep(0, length(true.means)),
        col="red", pch=21,  bg="red")
    }else{
      par(mfrow=c(1,1), mar=c(3,3,2,1), oma =c(1,1,1,1))
      #   NBiv_mix <- function(x, y, k, rho, mu_x, mu_y,
      #     sigma_1x, sigma_1y, sigma_2x,sigma_2y, p){
      #     a <- (2*pi*sigma_1x*sigma_1y*sqrt(1-rho^2))^(-1)
      #     a2 <- (2*pi*sigma_2x*sigma_2y*sqrt(1-rho^2))^(-1)
      #     distr <- list()
      #     for (j in 1:k){
      #     distr[[j]] <-
      #     p*a*exp(-.5*(1)*(1-rho^2)^(-1)*
      #         ( ( (x-mu_x[j])/sigma_1x )^2+
      #             ((y-mu_y[j])/sigma_1y)^2
      #             -2*rho*(x-mu_x[j])*(y-mu_y[j])/
      #             (sigma_1x*sigma_1y)   ))+
      #             (1-p)*a2*exp(-.5*(1)*(1-rho^2)^(-1)*
      #             ( ( (x-mu_x[j])/sigma_2x )^2+
      #             ((y-mu_y[j])/sigma_2y)^2
      #             -2*rho*(x-mu_x[j])*(y-mu_y[j])/
      #             (sigma_2x*sigma_2y)   ))
      # }
      #
      #     sum_vec <- matrix(NA, k, length(distr[[j]]))
      #     for (j in 1:k){
      #       sum_vec[j,] <- as.vector(distr[[j]])
      #     }
      #
      #     return(apply(sum_vec,2,sum))
      #
      #     }
      #
      #   xx<-seq(min(y[,1])-1, max(y[,1])+1, length.out = min(100, length(y[,1])/2))
      #   yy<-seq(min(y[,2])-1, max(y[,2])+1, length.out = min(100, length(y[,1])/2))
      #   mu_x=add[,1]
      #   mu_y=add[,2]
      #   # poniamo rho=1/2
      #   par(mfrow=c(1,1), oma= c(0,0,0,0))
      #   z<-outer(xx, yy, NBiv_mix, k = length(add[,1]),
      #     mu_x=mu_x, mu_y=mu_y, sigma_1x= add2[1], sigma_1y=add2[2],
      #     sigma_2x=add2[3], sigma_2y=add2[4], p =add2[5], rho=0.5)
      #   #Raw MCMC
      #   persp(xx, yy, z, theta=30, phi=30, xlab="x", ylab="y", zlab="f(x,y)",
      #     expand=0.5, ltheta=120,
      #     col = "lightblue", shade = 0.1, ticktype = "detailed" ) -> res
      #   points(trans3d(t(apply(mu_switch, c(2,3), mean))[,1],
      #     t(apply(mu_switch, c(2,3), mean))[,2], 0, pmat = res), col = 2, pch = 16)
      #   #Relabelled
      #    persp(xx, yy, z, theta=30, phi=30, xlab="x", ylab="y", zlab="f(x,y)",
      #     expand=0.5, ltheta=120,
      #      col = "lightblue",
      #      shade = 0.1, ticktype = "detailed",
      #      main=
      #        paste("Rel. estimates: method ",
      #          pivotal.criterion), cex.main=0.8) -> res
      #    points(trans3d(est[,1,pivotal.criterion],
      #      est[,2,pivotal.criterion], 0, pmat = res), col = 2, pch = 16)

      # 3d histogram

      xy <- y
      nbins <- 20
      x.bin <- seq(floor(min(xy[,1])),
        ceiling(max(xy[,1])), length=nbins)
      y.bin <- seq(floor(min(xy[,2])),
        ceiling(max(xy[,2])), length=nbins)
      freq <-  as.data.frame(table(findInterval(xy[,1],
        x.bin),findInterval(xy[,2], y.bin)))
      freq[,1] <- as.numeric(freq[,1])
      freq[,2] <- as.numeric(freq[,2])
      freq2D <- diag(nbins)*0
      freq2D[cbind(freq[,1], freq[,2])] <- freq[,3]

      #par(mfrow=c(1,2))
      #image(x.bin, y.bin, freq2D,
      #col=topo.colors(max(freq2D)))
      #contour(x.bin, y.bin, freq2D,
      #add=TRUE, col=rgb(1,1,1,.7))
      #palette(rainbow(max(freq2D)))
      #cols <- (freq2D[-1,-1] +
      #freq2D[-1,-(nbins-1)] +
      # freq2D[-(nbins-1),-(nbins-1)] +
      #freq2D[-(nbins-1),-1])/4
      res <- persp(x.bin, y.bin,
        freq2D, theta=30, phi=30, xlab="\n\n\nx",
        ylab="\n\n\ny", zlab="\n\n\nf(x,y)",
        expand=0.5, ltheta=120,
        col = "lightblue",
        shade = 0.1, ticktype = "detailed",
        main=
          paste("Rel. estimates"), cex.main=0.8)
      points(trans3d(est[,1],
        est[,2], 0,
        pmat = res), col = "red", pch = 16)


    }

  }
  # else if(type=="estimates_hist" & all(pivotal.criterion, c(1:6))){
  #     par(mfrow=c(3,2))
  #     hist(y, breaks=40, prob = TRUE,
  #       main=
  #       paste("Real data and relabelled estimates (", pivotal.criterion[1], ")" ) )
  #       points(est[,pivotal.criterion[1]], rep(0, length(true.means)),
  #       col="red", pch=21,  bg="red")
  #
  #     for (j in 2:6){
  #     hist(y, breaks=40, prob = TRUE,
  #     main=
  #     paste("Real data and relabelled estimates (", pivotal.criterion[j], ")" ) )
  #     points(est[,pivotal.criterion[j]], rep(0, length(true.means)),
  #       col="red", pch=21,  bg="red")
  #     }
  #
  #     }
  else if (type=="iter"){
    par(mfrow=c(1,1))
    barplot(n.iter, main="Proportion of valid iterations", ylim=c(0,1),
      xlab="Pivotal criterion", ylab="Prop.", names.arg=c(1:7))
  }

}



```


```{r pivotal_rel, fig.show='hold', fig.align='center'}
relab_est <- 
  pivotal_relabelling(mu_switch=output_bayes$mu_switch,
                 group=output_bayes$groupPost,
                 clustering=output_bayes$clust_sel,
                 Mu=output_bayes$Mu,
                 nMC = nMC)

par(mfrow=c(2,2), mar=c(5,4,2,1))

plot_pivotal(y= sim$y,
             est = relab_est$mu_rel_median,
             chains=relab_est$mu_rel_complete,
             type="chains",
             mu_switch=output_bayes$mu_switch,
             n.iter=relab_est$Final_it,
             true.means= output_bayes$Mu)


```

With the option `estimates_hist`, the user may visualize the new relabelled posterior estimates in the tridimensional space, plotted against the tridimensional data histogram. 

```{r persp, fig.align = 'center'}
plot_pivotal(y= sim$y,
             est = relab_est$mu_rel_median,
             chains=relab_est$mu_rel_complete,
             type="estimates_hist",
             mu_switch=output_bayes$mu_switch,
             n.iter=relab_est$Final_it,
             true.means= output_bayes$Mu)

```


## References

